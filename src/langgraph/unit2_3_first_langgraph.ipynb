{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32f9f914",
   "metadata": {},
   "source": [
    "# Project 1 - Building First Langgraph Model\n",
    "\n",
    "\n",
    "### Follow the instructions \n",
    "Here are [instructions](https://huggingface.co/learn/agents-course/unit2/langgraph/first_graph) for the tutorial that are helpful for this notebook.\n",
    "\n",
    "\n",
    "### Description:\n",
    "This project uses `langgraph`, a library that provides a framework for developing your agents with ease.\n",
    "\n",
    "We look at Agents here. \n",
    "\n",
    "### The Problem this Notebook Attempts to Solve\n",
    "\n",
    "Alfredâ€™s email processing system, where he needs to:\n",
    "\n",
    "* Read incoming emails\n",
    "\n",
    "* Classify them as spam or legitimate\n",
    "\n",
    "* Draft a preliminary response for legitimate emails\n",
    "\n",
    "* Send information to Mr. Wayne when legitimate (printing only)\n",
    "\n",
    "This example demonstrates how to structure a workflow with LangGraph that involves LLM-based decision-making. While this canâ€™t be considered an Agent as no tool is involved, this section focuses more on learning the LangGraph framework than Agents.\n",
    "\n",
    "### For this course, I am using \n",
    "\n",
    "\n",
    "see also [github code](https://github.com/huggingface/agents-course)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c591b1",
   "metadata": {},
   "source": [
    "## Load Imports\n",
    "\n",
    " `LangGraph` provides the graph structure, while `LangChain` offers convenient interfaces for working with LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d8f275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import TypedDict, List, Dict, Any, Optional\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Set your OpenAI API key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-xxxxx\"  # Replace with your actual API key\n",
    "\n",
    "# Initialize our LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) #temperature means here to be very precise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac063710",
   "metadata": {},
   "source": [
    "## Step 1: Define Our State\n",
    "\n",
    "In `LangGraph`, `State` is the central concept. It represents all the information that flows through our workflow.\n",
    "\n",
    "For Alfred's email processing system, we need to track:\n",
    "\n",
    "* The email being processed\n",
    "* Whether it's spam or not\n",
    "* The draft response (for legitimate emails)\n",
    "* Conversation history with the LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198023a9",
   "metadata": {},
   "source": [
    "```\n",
    "class EmailState(TypedDict):\n",
    "    # The email being processed\n",
    "    email: Dict[str, Any]  # Contains subject, sender, body, etc.\n",
    "\n",
    "    # Category of the email (inquiry, complaint, etc.)\n",
    "    email_category: Optional[str]\n",
    "\n",
    "    # Reason why the email was marked as spam\n",
    "    spam_reason: Optional[str]\n",
    "\n",
    "    # Analysis and decisions\n",
    "    is_spam: Optional[bool]\n",
    "    \n",
    "    # Response generation\n",
    "    email_draft: Optional[str]\n",
    "    \n",
    "    # Processing metadata\n",
    "    messages: List[Dict[str, Any]]  # Track conversation with LLM for analysis\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4633a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This class requires all key and value pairs to be present when creating an instance\n",
    "class EmailState(TypedDict):\n",
    "    email: Dict[str, Any]\n",
    "    is_spam: Optional[bool]\n",
    "    spam_reason: Optional[str]\n",
    "    email_category: Optional[str]\n",
    "    email_draft: Optional[str]\n",
    "    messages: List[Dict[str, Any]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a22081",
   "metadata": {},
   "source": [
    "### Step 2: Define Our Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc0800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(state: EmailState):\n",
    "    \"\"\"Alfred reads and logs the incoming email\"\"\"\n",
    "    email = state[\"email\"]\n",
    "    print(f\"Alfred is processing an email from {email['sender']} with subject: {email['subject']}\")\n",
    "    # No state changes needed here\n",
    "    return {}\n",
    "\n",
    "\n",
    "def classify_email(state: EmailState):\n",
    "    \"\"\"Alfred uses an LLM to determine if the email is spam or legitimate\"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler of Mr wayne and it's SECRET identity Batman, analyze this email and determine if it is spam or legitimate and should be brought to Mr wayne's attention.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "First, determine if this email is spam.\n",
    "answer with SPAM or HAM if it's legitimate. Only return the answer\n",
    "Answer :\n",
    "    \"\"\"\n",
    "\n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Simple logic to parse the response (in a real app, you'd want more robust parsing)\n",
    "    response_text = response.content.lower()\n",
    "    print(response_text)\n",
    "    is_spam = \"spam\" in response_text and \"ham\" not in response_text\n",
    "\n",
    "    # Extract a reason if it's spam\n",
    "    if not is_spam:\n",
    "        new_messages = state.get(\"messages\", []) + [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": response.content}\n",
    "        ]\n",
    "    else:\n",
    "        new_messages = state.get(\"messages\", [])\n",
    "\n",
    "    return {\n",
    "        \"is_spam\": is_spam,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "\n",
    "def handle_spam(state: EmailState):\n",
    "    \"\"\"Alfred discards spam email with a note\"\"\"\n",
    "    print(f\"Alfred has marked the email as spam.\")\n",
    "    print(\"The email has been moved to the spam folder.\")\n",
    "    return {}\n",
    "\n",
    "\n",
    "def drafting_response(state: EmailState):\n",
    "    \"\"\"Alfred drafts a preliminary response for legitimate emails\"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    # Prepare our prompt for the LLM\n",
    "    prompt = f\"\"\"\n",
    "As Alfred the butler, draft a polite preliminary response to this email.\n",
    "\n",
    "Email:\n",
    "From: {email['sender']}\n",
    "Subject: {email['subject']}\n",
    "Body: {email['body']}\n",
    "\n",
    "Draft a brief, professional response that Mr. Wayne can review and personalize before sending.\n",
    "    \"\"\"\n",
    "    # Call the LLM\n",
    "    messages = [HumanMessage(content=prompt)]\n",
    "    response = model.invoke(messages)\n",
    "\n",
    "    # Update messages for tracking\n",
    "    new_messages = state.get(\"messages\", []) + [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\"role\": \"assistant\", \"content\": response.content}\n",
    "    ]\n",
    "\n",
    "    # Return state updates\n",
    "    return {\n",
    "        \"email_draft\": response.content,\n",
    "        \"messages\": new_messages\n",
    "    }\n",
    "\n",
    "\n",
    "def notify_mr_wayne(state: EmailState):\n",
    "    \"\"\"Alfred notifies Mr. Wayne about the email and presents the draft response\"\"\"\n",
    "    email = state[\"email\"]\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Sir, you've received an email from {email['sender']}.\")\n",
    "    print(f\"Subject: {email['subject']}\")\n",
    "    print(\"\\nI've prepared a draft response for your review:\")\n",
    "    print(\"-\" * 50)\n",
    "    print(state[\"email_draft\"])\n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "    return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ebffa",
   "metadata": {},
   "source": [
    "## Step 3: Define Our Routing Logic\n",
    "We need a function to determine which path to take after classification:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352ef139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define routing logic\n",
    "def route_email(state: EmailState) -> str:\n",
    "    \"\"\"Determine the next step based on spam classification\"\"\"\n",
    "    if state[\"is_spam\"]:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"legitimate\"\n",
    "\n",
    "\n",
    "# Create the graph\n",
    "email_graph = StateGraph(EmailState)\n",
    "\n",
    "# Add nodes\n",
    "email_graph.add_node(\"read_email\", read_email)  # the read_email node executes the read_mail function\n",
    "email_graph.add_node(\"classify_email\", classify_email)  # the classify_email node will execute the classify_email function\n",
    "email_graph.add_node(\"handle_spam\", handle_spam)  #same logic\n",
    "email_graph.add_node(\"drafting_response\", drafting_response)  #same logic\n",
    "email_graph.add_node(\"notify_mr_wayne\", notify_mr_wayne)  # same logic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7421920a",
   "metadata": {},
   "source": [
    "### Step 4: Create the StateGraph and Define Edges\n",
    "\n",
    "Now we connected\n",
    "\n",
    "Notice how we use the special END node provided by LangGraph. This indicates terminal states where the workflow completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db295ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edges\n",
    "email_graph.add_edge(START, \"read_email\")  # After starting we go to the \"read_email\" node\n",
    "\n",
    "email_graph.add_edge(\"read_email\", \"classify_email\")  # after_reading we classify\n",
    "\n",
    "# Add conditional edges\n",
    "email_graph.add_conditional_edges(\n",
    "    \"classify_email\",  # after classify, we run the \"route_email\" function\"\n",
    "    route_email,\n",
    "    {\n",
    "        \"spam\": \"handle_spam\",  # if it return \"Spam\", we go the \"handle_span\" node\n",
    "        \"legitimate\": \"drafting_response\"  # and if it's legitimate, we go to the \"drafting response\" node\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add final edges\n",
    "email_graph.add_edge(\"handle_spam\", END)  # after handling spam we always end\n",
    "email_graph.add_edge(\"drafting_response\", \"notify_mr_wayne\")\n",
    "email_graph.add_edge(\"notify_mr_wayne\", END)  # after notifyinf Me wayne, we can end  too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282026e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the graph\n",
    "compiled_graph = email_graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a43a8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(compiled_graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612f81c",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Example emails for testing\n",
    "legitimate_email = {\n",
    "    \"sender\": \"Joker\",\n",
    "    \"subject\": \"Found you Batman ! \",\n",
    "    \"body\": \"Mr. Wayne,I found your secret identity ! I know you're batman ! Ther's no denying it, I have proof of that and I'm coming to find you soon. I'll get my revenge. JOKER\"\n",
    "}\n",
    "\n",
    "spam_email = {\n",
    "    \"sender\": \"Crypto bro\",\n",
    "    \"subject\": \"The best investment of 2025\",\n",
    "    \"body\": \"Mr Wayne, I just launched an ALT coin and want you to buy some !\"\n",
    "}\n",
    "# Process legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke({\n",
    "    \"email\": legitimate_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})\n",
    "\n",
    "# Process spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke({\n",
    "    \"email\": spam_email,\n",
    "    \"is_spam\": None,\n",
    "    \"spam_reason\": None,\n",
    "    \"email_category\": None,\n",
    "    \"email_draft\": None,\n",
    "    \"messages\": []\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e76696",
   "metadata": {},
   "source": [
    "---\n",
    "## Optional:\n",
    "\n",
    "\n",
    "## Step 5: Inspecting Our Mail Sorting Agent with Langfuse ðŸ“¡\n",
    "\n",
    "As Alfred fine-tunes the Main Sorting Agent, he's growing weary of debugging its runs. Agents, by nature, are unpredictable and difficult to inspect. But since he aims to build the ultimate Spam Detection Agent and deploy it in production, he needs robust traceability for future monitoring and analysis.\n",
    "\n",
    "To do this, Alfred can use an observability tool such as `Langfuse` to trace and monitor the inner steps of the agent.\n",
    "\n",
    "First, we need to install the necessary dependencies: namely, `langfuse`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27900f55",
   "metadata": {},
   "source": [
    "Next, we set the Langfuse API keys and host address as environment variables. You can get your Langfuse credentials by signing up for [Langfuse Cloud](https://cloud.langfuse.com/) or [self-hosting Langfuse](https://langfuse.com/self-hosting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79346aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys for your project from the project settings page: https://cloud.langfuse.com\n",
    "os.environ[\"LANGFUSE_PUBLIC_KEY\"] = \"pk-lf-...\"\n",
    "os.environ[\"LANGFUSE_SECRET_KEY\"] = \"sk-lf-...\"\n",
    "os.environ[\"LANGFUSE_HOST\"] = \"https://cloud.langfuse.com\"  # ðŸ‡ªðŸ‡º EU region\n",
    "# os.environ[\"LANGFUSE_HOST\"] = \"https://us.cloud.langfuse.com\" # ðŸ‡ºðŸ‡¸ US region"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11de45d",
   "metadata": {},
   "source": [
    "Now, we configure the [Langfuse](https://langfuse.com/docs/integrations/langchain/tracing#add-langfuse-to-your-langchain-application) callback_handler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd697ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.langchain import CallbackHandler\n",
    "\n",
    "# Initialize Langfuse CallbackHandler for LangGraph/Langchain (tracing)\n",
    "langfuse_handler = CallbackHandler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9021d",
   "metadata": {},
   "source": [
    "We then add config={\"callbacks\": [langfuse_handler]} to the invocation of the agents and run them again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f2218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process legitimate email\n",
    "print(\"\\nProcessing legitimate email...\")\n",
    "legitimate_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": legitimate_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")\n",
    "\n",
    "# Process spam email\n",
    "print(\"\\nProcessing spam email...\")\n",
    "spam_result = compiled_graph.invoke(\n",
    "    input={\n",
    "        \"email\": spam_email,\n",
    "        \"is_spam\": None,\n",
    "        \"draft_response\": None,\n",
    "        \"messages\": []\n",
    "    },\n",
    "    config={\"callbacks\": [langfuse_handler]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e10c292",
   "metadata": {},
   "source": [
    "Alfred is now connected ðŸ”Œ! The runs from LangGraph are being logged in Langfuse, giving him full visibility into the agent's behavior. With this setup, he's ready to revisit previous runs and refine his Mail Sorting Agent even further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-agent-hugging-face-course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
